{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hor4d6I5SLbS"
      },
      "source": [
        "# AI-PBPK model project: hyperparameters tuning with BayesSearchCV \n",
        "Author: Wei-Chun Chou  \n",
        "Date created: 2022/06/09  \n",
        "Description: In this study, we used lightGBM and Deep nerual network model to predict the require parameter which can be inputed into the PBPK model  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58pDV7v7cPLz"
      },
      "source": [
        "# Install and import required python pacakges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKlJya_nYv-p"
      },
      "outputs": [],
      "source": [
        "# Install python pacakges\n",
        "#!pip install pycaret==2.3.10 markupsafe==2.0.1 pyyaml==5.4.1 -qq\n",
        "!pip install -q lightgbm # install the lightgbm package\n",
        "!pip install -q scikit-optimize # install the package used for Bayesian optimization\n",
        "!pip install -q scikeras[tensorflow]\n",
        "!pip install -q keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCuWQXqSapTf"
      },
      "outputs": [],
      "source": [
        "#Install basic python pcakges\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rm-dOROZUS7"
      },
      "source": [
        "# Link to google drive and set up your project folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZkkXjpxZZFQ",
        "outputId": "05f77379-b6c4-4741-8350-a8691cd12d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount drive to google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set your working directory to a speicifc folder in your Google Drive\n",
        "# The base Google Drive directory\n",
        "root_dir = \"/content/drive/My Drive/Colab Notebooks/AI-Toxicology\"\n",
        "\n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"/Project_2_AI-PBPK/\" # Name your project here. Please instead the \"my project folder\" to your prefer name\n",
        "\n",
        "# Make sure that floder exists. If not, automatically create a new folder\n",
        "if (not os.path.isdir(root_dir + project_folder)):\n",
        "  os.mkdir(root_dir + project_folder)\n",
        "  print(root_dir + project_folder + 'did not exist but was created.')\n",
        "\n",
        "# Change the OS to use your project folder as the working directory\n",
        "os.chdir(root_dir + project_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUHWGwQGZ5vg"
      },
      "source": [
        "# Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7Vgo360Z7zc"
      },
      "outputs": [],
      "source": [
        "# importer Data\n",
        "Data = pd.read_csv(os.path.join(root_dir + project_folder + \"Data.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMB4qMCBZIfh"
      },
      "source": [
        "# Data preprocessing I: missing Values  \n",
        "Most Machine leanring algorithms canot work with missing features. So, we need to use `SimpleImputer` to replace missing values with median, mean or frequently used values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jpaQvf0ZIHN",
        "outputId": "601b8721-3278-46c0-cbba-b65d8dd6d6cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID               0\n",
              "Type             0\n",
              "TS               0\n",
              "HD              36\n",
              "Zeta            44\n",
              "Charge          40\n",
              "Shape            0\n",
              "TM               0\n",
              "CT               0\n",
              "TSz             31\n",
              "TW               0\n",
              "Dose             0\n",
              "BW               0\n",
              "DE24             0\n",
              "DE168            0\n",
              "Demax            0\n",
              "KTRESrelease     0\n",
              "KTRESmax         0\n",
              "KTRES50          0\n",
              "KTRESn           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# see how many missing values in your dataset\n",
        "Data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqRmHwbIT_mI"
      },
      "outputs": [],
      "source": [
        "# Remove the row with missing data\n",
        "Data=Data.dropna() # you can use 'subset' (e.g., dropna(subset='HD')) to remove the missing value in specific column"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(Data)\n",
        "df_X = df[[\"Type\",\"TS\",\"HD\",\"Zeta\",\"Charge\",\"Shape\", \"TM\", \"CT\", \"TSz\", \"TW\"]]\n",
        "df_y = df[[\"KTRESrelease\",\"KTRESn\",\"KTRESmax\", \"KTRES50\"]]"
      ],
      "metadata": {
        "id": "co78bDfayL20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGgYnneRR4ta"
      },
      "outputs": [],
      "source": [
        "## Replace mising value with \"Mean\" or \"Frequency values\"\n",
        "imputer_mean = SimpleImputer(strategy='mean', missing_values=np.nan)\n",
        "imputer_freq = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
        "cols_num = ['HD','Zeta',\"TSz\",'TW']\n",
        "cols_label = ['Type','TS','Charge','Shape','TM','CT']\n",
        "\n",
        "imputer_mean = imputer_mean.fit(df_X[cols_num])\n",
        "imputer_freq = imputer_freq.fit(df_X[cols_label])\n",
        "df_X[cols_num] = imputer_mean.transform(df_X[cols_num])\n",
        "df_X[cols_label] = imputer_freq.transform(df_X[cols_label])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHk_ilEgVsTh"
      },
      "source": [
        "# 3. Taking care of Categorical Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN-rRyZuz9oG"
      },
      "outputs": [],
      "source": [
        "test_X = df_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbQesdjAVuXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d04805-4e83-4faf-a020-96757abdae06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Type  TS     HD  Zeta  Charge  Shape  TM  CT    TSz     TW\n",
            "4       1   0   68.4   9.3       0      2   3  13  0.175  0.210\n",
            "5       1   1  166.0   6.0       0      6   4  16  1.100  1.320\n",
            "6       1   0  175.6   5.0       0      6   4  16  1.100  1.320\n",
            "7       1   1  104.2  10.0       0      6   4  16  1.100  1.320\n",
            "8       1   1   64.2  15.0       0      6   4  16  1.100  1.320\n",
            "..    ...  ..    ...   ...     ...    ...  ..  ..    ...    ...\n",
            "373     2   1   92.0   0.0       2      6   3   1  0.530  0.636\n",
            "374     2   1   92.0   0.0       2      6   3   1  0.530  0.636\n",
            "375     2   1   92.0   0.0       2      6   3   1  0.530  0.636\n",
            "376     2   1  122.5  13.2       0      6   3   6  0.300  0.360\n",
            "377     2   1  190.5  10.1       0      4   1  11  0.100  0.120\n",
            "\n",
            "[288 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode labels of multiple columns at once\n",
        "test_X[cols_label] = test_X[cols_label].apply(LabelEncoder().fit_transform)\n",
        "\n",
        "print(test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wiZI76Qkf8H"
      },
      "source": [
        "# 4. Model normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tvIrzNGYsYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce1cc21-f414-4ccb-ac2d-7557ebe41af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           HD      Zeta       TSz        TW\n",
            "0    0.139468  0.033917  0.087079  0.087079\n",
            "1    0.355876  0.021882  0.606742  0.606742\n",
            "2    0.377162  0.018235  0.606742  0.606742\n",
            "3    0.218847  0.036470  0.606742  0.606742\n",
            "4    0.130155  0.054705  0.606742  0.606742\n",
            "..        ...       ...       ...       ...\n",
            "283  0.191796  0.000000  0.286517  0.286517\n",
            "284  0.191796  0.000000  0.286517  0.286517\n",
            "285  0.191796  0.000000  0.286517  0.286517\n",
            "286  0.259424  0.048140  0.157303  0.157303\n",
            "287  0.410200  0.036834  0.044944  0.044944\n",
            "\n",
            "[288 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "cols_num = ['HD','Zeta',\"TSz\",\"TW\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "mscaler = MinMaxScaler()\n",
        "\n",
        "Data_num_tr = pd.DataFrame(mscaler.fit_transform(test_X[cols_num]))\n",
        "Data_num_tr.columns = list(test_X[cols_num].columns)\n",
        "print(Data_num_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojg8DNmXvhTL"
      },
      "source": [
        "# Onehot encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpWvmFhZvkip",
        "outputId": "534e1b4c-9cff-46a5-bf07-ab6669fb7ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     TS_0  TS_1  TS_2  TS_3  TM_0  TM_1  TM_2  TM_3  TM_4  CT_0  ...  CT_15  \\\n",
            "0     1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
            "1     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "2     1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "3     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "4     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
            "283   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
            "284   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
            "285   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
            "286   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
            "287   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
            "\n",
            "     CT_16  CT_17  Shape_0  Shape_1  Shape_2  Shape_3  Shape_4  Shape_5  \\\n",
            "0      0.0    0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
            "1      1.0    0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "2      1.0    0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "3      1.0    0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "4      1.0    0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "..     ...    ...      ...      ...      ...      ...      ...      ...   \n",
            "283    0.0    0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "284    0.0    0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "285    0.0    0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "286    0.0    0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "287    0.0    0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
            "\n",
            "     Shape_6  \n",
            "0        0.0  \n",
            "1        1.0  \n",
            "2        1.0  \n",
            "3        1.0  \n",
            "4        1.0  \n",
            "..       ...  \n",
            "283      1.0  \n",
            "284      1.0  \n",
            "285      1.0  \n",
            "286      1.0  \n",
            "287      0.0  \n",
            "\n",
            "[288 rows x 34 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_encoder = OneHotEncoder(sparse=False)\n",
        "cols_label_1hot = ['TS','TM',\"CT\",'Shape']\n",
        "data_cat_1hot = pd.DataFrame(cat_encoder.fit_transform(test_X[cols_label_1hot]))\n",
        "data_cat_1hot.columns = cat_encoder.get_feature_names(cols_label_1hot)\n",
        "\n",
        "print(data_cat_1hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbU01eLqx1TY",
        "outputId": "f152af5a-cd68-41cb-e871-c37d14bc8705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           HD      Zeta       TSz        TW  TS_0  TS_1  TS_2  TS_3  TM_0  \\\n",
            "0    0.139468  0.033917  0.087079  0.087079   1.0   0.0   0.0   0.0   0.0   \n",
            "1    0.355876  0.021882  0.606742  0.606742   0.0   1.0   0.0   0.0   0.0   \n",
            "2    0.377162  0.018235  0.606742  0.606742   1.0   0.0   0.0   0.0   0.0   \n",
            "3    0.218847  0.036470  0.606742  0.606742   0.0   1.0   0.0   0.0   0.0   \n",
            "4    0.130155  0.054705  0.606742  0.606742   0.0   1.0   0.0   0.0   0.0   \n",
            "..        ...       ...       ...       ...   ...   ...   ...   ...   ...   \n",
            "283  0.191796  0.000000  0.286517  0.286517   0.0   1.0   0.0   0.0   0.0   \n",
            "284  0.191796  0.000000  0.286517  0.286517   0.0   1.0   0.0   0.0   0.0   \n",
            "285  0.191796  0.000000  0.286517  0.286517   0.0   1.0   0.0   0.0   0.0   \n",
            "286  0.259424  0.048140  0.157303  0.157303   0.0   1.0   0.0   0.0   0.0   \n",
            "287  0.410200  0.036834  0.044944  0.044944   0.0   1.0   0.0   0.0   0.0   \n",
            "\n",
            "     TM_1  ...  CT_15  CT_16  CT_17  Shape_0  Shape_1  Shape_2  Shape_3  \\\n",
            "0     0.0  ...    0.0    0.0    0.0      0.0      0.0      1.0      0.0   \n",
            "1     0.0  ...    0.0    1.0    0.0      0.0      0.0      0.0      0.0   \n",
            "2     0.0  ...    0.0    1.0    0.0      0.0      0.0      0.0      0.0   \n",
            "3     0.0  ...    0.0    1.0    0.0      0.0      0.0      0.0      0.0   \n",
            "4     0.0  ...    0.0    1.0    0.0      0.0      0.0      0.0      0.0   \n",
            "..    ...  ...    ...    ...    ...      ...      ...      ...      ...   \n",
            "283   0.0  ...    0.0    0.0    0.0      0.0      0.0      0.0      0.0   \n",
            "284   0.0  ...    0.0    0.0    0.0      0.0      0.0      0.0      0.0   \n",
            "285   0.0  ...    0.0    0.0    0.0      0.0      0.0      0.0      0.0   \n",
            "286   0.0  ...    0.0    0.0    0.0      0.0      0.0      0.0      0.0   \n",
            "287   1.0  ...    0.0    0.0    0.0      0.0      0.0      0.0      0.0   \n",
            "\n",
            "     Shape_4  Shape_5  Shape_6  \n",
            "0        0.0      0.0      0.0  \n",
            "1        0.0      0.0      1.0  \n",
            "2        0.0      0.0      1.0  \n",
            "3        0.0      0.0      1.0  \n",
            "4        0.0      0.0      1.0  \n",
            "..       ...      ...      ...  \n",
            "283      0.0      0.0      1.0  \n",
            "284      0.0      0.0      1.0  \n",
            "285      0.0      0.0      1.0  \n",
            "286      0.0      0.0      1.0  \n",
            "287      1.0      0.0      0.0  \n",
            "\n",
            "[288 rows x 38 columns]\n"
          ]
        }
      ],
      "source": [
        "cols_label_bi = ['Type',\"TS\",'Charge']\n",
        "data_cat_bi = test_X[cols_label_bi]\n",
        "preData=pd.concat([Data_num_tr, data_cat_1hot], axis=1)\n",
        "print(preData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuxtXCCMMNqh"
      },
      "source": [
        "# Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HIlb7ZSMP3u",
        "outputId": "89b72ea4-477d-4472-9f2e-661e02934b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           HD      Zeta  TM_0  TM_3  CT_1  CT_3  CT_5  CT_13  Shape_2  Shape_4\n",
            "0    0.139468  0.033917   0.0   1.0   0.0   0.0   0.0    1.0      1.0      0.0\n",
            "1    0.355876  0.021882   0.0   0.0   0.0   0.0   0.0    0.0      0.0      0.0\n",
            "2    0.377162  0.018235   0.0   0.0   0.0   0.0   0.0    0.0      0.0      0.0\n",
            "3    0.218847  0.036470   0.0   0.0   0.0   0.0   0.0    0.0      0.0      0.0\n",
            "4    0.130155  0.054705   0.0   0.0   0.0   0.0   0.0    0.0      0.0      0.0\n",
            "..        ...       ...   ...   ...   ...   ...   ...    ...      ...      ...\n",
            "283  0.191796  0.000000   0.0   1.0   1.0   0.0   0.0    0.0      0.0      0.0\n",
            "284  0.191796  0.000000   0.0   1.0   1.0   0.0   0.0    0.0      0.0      0.0\n",
            "285  0.191796  0.000000   0.0   1.0   1.0   0.0   0.0    0.0      0.0      0.0\n",
            "286  0.259424  0.048140   0.0   1.0   0.0   0.0   0.0    0.0      0.0      0.0\n",
            "287  0.410200  0.036834   0.0   0.0   0.0   0.0   0.0    0.0      0.0      1.0\n",
            "\n",
            "[288 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "# pearson's correlation feature selection for numeric input and numeric output\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "# generate dataset\n",
        "#X, y = make_regression(n_samples=100, n_features=100, n_informative=10)\n",
        "# define feature selection\n",
        "fs = SelectKBest(score_func=f_regression, k=10)\n",
        "# apply feature selection\n",
        "X_selected = pd.DataFrame(fs.fit_transform(preData, df_y['KTRESmax']))\n",
        "cols = fs.get_feature_names_out()\n",
        "X_selected.columns = cols\n",
        "print(X_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMV-geDwtEYJ"
      },
      "outputs": [],
      "source": [
        "y_re = df_y['KTRESmax']\n",
        "X_re = preData"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFHtUggbvgCs"
      },
      "source": [
        "# LightGbm model with pretest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC,SVR\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import Ridge"
      ],
      "metadata": {
        "id": "X_lZyntYcmJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_to_run = [Ridge(), SVR(), RandomForestRegressor(), xgb.XGBRegressor(), lgb.LGBMRegressor()]\n",
        "\n",
        "model_parm_search = [\n",
        "    { # 1st parm corresponding to linear\n",
        "     'alpha': Real(1e-5, 100, prior='log-uniform'),\n",
        "     \"solver\":Categorical(['svd', 'cholesky', 'lsqr', 'sag']),\n",
        "     'fit_intercept':Categorical([\"True\", \"False\"]),\n",
        "    },\n",
        "    \n",
        "    { # 2nd parm corresponding to SVR\n",
        "     #'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "     \"kernel\":Categorical(['linear','poly','rbf','sigmoid']),\n",
        "     'gamma':Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "     \"epsilon\":Integer(0,1),\n",
        "    },\n",
        "\n",
        "    { # 3rd parm corresponding to RandomForestRegressor\n",
        "     'max_depth': Integer(3, 12),\n",
        "     'n_estimators': Integer(100, 1000),\n",
        "     'max_features': Integer(10, 38),\n",
        "    },\n",
        "\n",
        "    { # 4th param grid, corresponding to XGBRegressor\n",
        "     'learning_rate': Real(1e-4, 1.0, 'log-uniform'),\n",
        "     'colsample_bytree': Real(0.1, 0.9),\n",
        "     'n_estimators': Integer(100, 1000),\n",
        "     'reg_alpha': Real(1, 1.5,'log-uniform'),\n",
        "     'reg_lambda': Real(1, 1.5,'log-uniform'),\n",
        "    },\n",
        "\n",
        "    { # 5th param grid, corresponding to LGBMRegressor\n",
        "     #'learning_rate': Real(1e-4, 1.0, 'log-uniform'),\n",
        "     'n_estimators': Integer(100, 1000),\n",
        "     'max_depth': Integer(3, 12),\n",
        "     'reg_alpha': Real(1, 1.5,'log-uniform'),\n",
        "     'reg_alpha': Real(1, 1.5,'log-uniform'),\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "ch6IKH-Rdd89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_re, y_re, test_size = 0.2, random_state=2)\n"
      ],
      "metadata": {
        "id": "89WfqJ1VfSpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=2)\n",
        "\n",
        "for i, model in enumerate(models_to_run):\n",
        "   # build the Bayesian search model\n",
        "   bs = BayesSearchCV(\n",
        "       estimator=model,\n",
        "       search_spaces=model_parm_search[i],\n",
        "       cv = cv,\n",
        "       n_iter = 90,\n",
        "       n_jobs = -1, \n",
        "       scoring = \"r2\",\n",
        "       #return_train_score=True,\n",
        "       random_state = 2\n",
        "   )\n",
        "\n",
        "   bs.fit(X_train, y_train)\n",
        "   \n",
        "   model    = bs.best_estimator_\n",
        "   test_preds = model.predict(X_test)\n",
        "   train_preds = model.predict(X_train)\n",
        "   all_preds  = model.predict(X_re)\n",
        "   y_obs    = y_re.tolist()\n",
        "    \n",
        "   r2_kfolds = cross_val_score(model, X_train, y_train, cv = cv, n_jobs=-1, scoring='r2')\n",
        "   rmse_kfolds = cross_val_score(model, X_train, y_train, cv = cv, n_jobs=-1, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "   print('\\nThe 5-CV rmse Score was:', rmse_kfolds.mean()) \n",
        "   print('With a standard deviation of:', rmse_kfolds.std())\n",
        "   print('Test rmse socre: %.2f' %mse(y_test, test_preds, squared=False))\n",
        "\n",
        "   print('\\nThe 5-CV R2 Score was:', r2_kfolds.mean()) \n",
        "   print('With a standard deviation of:', r2_kfolds.std())\n",
        "   print(\"Test R2 Score : %.2f\" %r2_score(y_test, test_preds))\n",
        "   print(\"Train R2 Score : %.2f\" %r2_score(y_train, train_preds))\n",
        "   print(\"All R2 Score : %.2f\" %r2_score(y_obs, all_preds)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKLyptYZe9oU",
        "outputId": "3e23a8fb-6c92-4836-bb6a-4dd915e3efa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The 5-CV rmse Score was: -3.5807459698496826\n",
            "With a standard deviation of: 1.1744234092989412\n",
            "Test rmse socre: 2.25\n",
            "\n",
            "The 5-CV R2 Score was: -0.026898918910597834\n",
            "With a standard deviation of: 0.07037833784195785\n",
            "Test R2 Score : 0.05\n",
            "Train R2 Score : 0.05\n",
            "All R2 Score : 0.05\n",
            "\n",
            "The 5-CV rmse Score was: -3.5787125964431903\n",
            "With a standard deviation of: 1.2417622068251521\n",
            "Test rmse socre: 2.29\n",
            "\n",
            "The 5-CV R2 Score was: -0.005476824846697759\n",
            "With a standard deviation of: 0.02046192285085156\n",
            "Test R2 Score : 0.02\n",
            "Train R2 Score : 0.05\n",
            "All R2 Score : 0.05\n",
            "\n",
            "The 5-CV rmse Score was: -3.3935179682934935\n",
            "With a standard deviation of: 1.0866939802314437\n",
            "Test rmse socre: 1.84\n",
            "\n",
            "The 5-CV R2 Score was: 0.018229100154173516\n",
            "With a standard deviation of: 0.27203804432961853\n",
            "Test R2 Score : 0.36\n",
            "Train R2 Score : 0.60\n",
            "All R2 Score : 0.58\n",
            "[22:58:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "The 5-CV rmse Score was: -3.364505771688613\n",
            "With a standard deviation of: 1.1730343628842654\n",
            "Test rmse socre: 1.87\n",
            "\n",
            "The 5-CV R2 Score was: 0.05130286735907994\n",
            "With a standard deviation of: 0.2887542524569793\n",
            "Test R2 Score : 0.34\n",
            "Train R2 Score : 0.43\n",
            "All R2 Score : 0.42\n",
            "\n",
            "The 5-CV rmse Score was: -3.5883922731018965\n",
            "With a standard deviation of: 1.0087148390620266\n",
            "Test rmse socre: 1.92\n",
            "\n",
            "The 5-CV R2 Score was: -0.1522140247220683\n",
            "With a standard deviation of: 0.4369266855793643\n",
            "Test R2 Score : 0.31\n",
            "Train R2 Score : 0.65\n",
            "All R2 Score : 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep nerual network model with keras"
      ],
      "metadata": {
        "id": "bRt_8P_6x48L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import basic packages\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import scikeras\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.colors as colors\n",
        "import matplotlib as mpl\n",
        "\n",
        "# import keras related packages\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers \n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras_tuner import BayesianOptimization\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner import Objective\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "nO6_s9n-x6l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_re.to_numpy()\n",
        "y = y_re.to_numpy()\n",
        "# summarize shape\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FWITGxXx9wu",
        "outputId": "37e1da75-8346-4711-a1d3-801d8e55f397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288, 38) (288,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state=2)"
      ],
      "metadata": {
        "id": "DbJhSWKvx_Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning Model with Keras Tuner"
      ],
      "metadata": {
        "id": "8-KGR9Q9yBnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  \n",
        "  # Input layer\n",
        "  model.add(Dense(units = hp.Int('dense-bot', min_value=38, \n",
        "             max_value=128, step=12, default=38),\n",
        "             activation = hp.Choice(\n",
        "                 'dense_activation',\n",
        "                    values=['relu', 'tanh', 'sigmoid'],\n",
        "                    default='relu'),\n",
        "             input_shape=(X.shape[1],)))\n",
        "  \n",
        "\n",
        "  # Tune the number of units in the each dense layer \n",
        "  for i in range (hp.Int('num_dense_layers',1,5)):\n",
        "    model.add(Dense(units=hp.Int('dense_'+str(i), min_value=50, max_value=512, step=25),\n",
        "          activation = hp.Choice('act_l1',['relu','tanh','sigmoid'])))\n",
        "    \n",
        "    # Tune the droput rate in the each dense layer\n",
        "    model.add(Dropout(hp.Float('dropout_'+ str(i), min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "  \n",
        "  # add output    \n",
        "  model.add(layers.Dense(1,activation='linear'))\n",
        "\n",
        "  hp_optimizer=hp.Choice('Optimizer', values=['Adam', 'SGD'])\n",
        "  \n",
        "  if hp_optimizer == 'Adam':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
        "  \n",
        "  elif hp_optimizer == 'SGD':\n",
        "     hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
        "     nesterov=True\n",
        "     momentum=0.9\n",
        "  \n",
        "  model.compile(\n",
        "    optimizer=hp_optimizer,\n",
        "    loss='mse',\n",
        "    metrics=['mse'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "Gwt-aUZFyCeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the model code work correctly\n",
        "import keras_tuner\n",
        "build_model(keras_tuner.HyperParameters())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdmZuBgzyHBE",
        "outputId": "05a0f27f-10b5-4f57-d717-7952a4caa5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f521f6824d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed the random number generator to reproduce the same results\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(2)"
      ],
      "metadata": {
        "id": "oY7PRVuuiCA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_bo = BayesianOptimization(\n",
        "            hypermodel = build_model,\n",
        "            objective = 'val_mse',\n",
        "            max_trials = 10,\n",
        "            overwrite = True,\n",
        "            executions_per_trial=1)"
      ],
      "metadata": {
        "id": "XUlYhZk6yIUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_bo.search(X_train, y_train, \n",
        "        validation_data=(X_test, y_test),\n",
        "        batch_size = 32,\n",
        "        epochs = 1000, verbose = 0)"
      ],
      "metadata": {
        "id": "dEyDM1SDyR2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 2 models\n",
        "best_params=tuner_bo.get_best_hyperparameters()\n",
        "best_params[0].values"
      ],
      "metadata": {
        "id": "kezHsC4cyVCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2c3722-cd8e-412c-a57d-3e279ad6570d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense-bot': 62,\n",
              " 'dense_activation': 'relu',\n",
              " 'num_dense_layers': 5,\n",
              " 'dense_0': 150,\n",
              " 'act_l1': 'relu',\n",
              " 'dropout_0': 0.0,\n",
              " 'Optimizer': 'Adam',\n",
              " 'learning_rate': 0.1,\n",
              " 'dense_1': 50,\n",
              " 'dropout_1': 0.0,\n",
              " 'dense_2': 50,\n",
              " 'dropout_2': 0.4,\n",
              " 'dense_3': 500,\n",
              " 'dropout_3': 0.0,\n",
              " 'dense_4': 500,\n",
              " 'dropout_4': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model= tuner_bo.get_best_models()[0]\n",
        "best_model.summary()\n"
      ],
      "metadata": {
        "id": "eNO8jvOzyZMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8b661b-f40f-458e-8f04-4e7619c7b7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 62)                2418      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 150)               9450      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 150)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                7550      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 500)               25500     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 500)               250500    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 298,469\n",
            "Trainable params: 298,469\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "best_model = tuner_bo.get_best_models()[0] \n",
        "\n",
        "test_preds = best_model.predict(X_test)\n",
        "train_preds = best_model.predict(X_train)\n",
        "all_preds  = best_model.predict(X_re)\n",
        "y_obs    = y_re.tolist()\n",
        "\n",
        "print(\"\\nTest R2 Score : %.2f\" %r2_score(y_test, test_preds))\n",
        "print(\"Train R2 Score : %.2f\" %r2_score(y_train, train_preds))\n",
        "print(\"All R2 Score : %.2f\" %r2_score(y_obs, all_preds))\n",
        "print('Test rmse socre: %.2f' %mse(y_test, test_preds, squared=False))\n"
      ],
      "metadata": {
        "id": "lXuWobZLykBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4432ea-dc91-4104-e607-dd7235fc50e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "\n",
            "Test R2 Score : 0.89\n",
            "Train R2 Score : 0.85\n",
            "All R2 Score : 0.86\n",
            "Test rmse socre: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model and architecture to single file\n",
        "best_model.save(\"KTRESmax_best_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coHvp6pX2VoF",
        "outputId": "1936f806-cf03-4ec3-f461-edbac6421e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_v2 = load_model('KTRESmax_best_model.h5')\n",
        "test_preds_v2 = best_model_v2.predict(X_test)\n",
        "train_preds_v2 = best_model_v2.predict(X_train)\n",
        "all_preds_v2  = best_model_v2.predict(X_re)\n",
        "y_obs    = y_re.tolist()\n",
        "\n",
        "print(\"\\nTest R2 Score : %.2f\" %r2_score(y_test, test_preds_v2))\n",
        "print(\"Train R2 Score : %.2f\" %r2_score(y_train, train_preds_v2))\n",
        "print(\"All R2 Score : %.2f\" %r2_score(y_obs, all_preds_v2))\n",
        "print('Test rmse socre: %.2f' %mse(y_test, test_preds, squared=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s63-erx62YrL",
        "outputId": "659273bd-0bc1-4b40-cc4e-a764f8ed3160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "\n",
            "Test R2 Score : 0.89\n",
            "Train R2 Score : 0.85\n",
            "All R2 Score : 0.86\n",
            "Test rmse socre: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the R-squared value on scatterplot with regression model "
      ],
      "metadata": {
        "id": "HlRAyoMh5f6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create basic catterplot\n",
        "plt.plot(y_obs, all_preds,'o')\n",
        "\n",
        "# obtain m (slope) and b(intercept) of linear regression line\n",
        "m, b = np.polyfit(y_obs, all_preds, 1)\n",
        "\n",
        "# add linear regression line to scatterplot\n",
        "plt.plot(y_obs, m*y_obs+b)"
      ],
      "metadata": {
        "id": "nE97Ys6l5E-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-fold cross validation"
      ],
      "metadata": {
        "id": "ILUQIgT0ymxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "\n",
        "dnn_best_model = tuner_bo.get_best_models()[0]  \n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=2)\n",
        "cvr2scores = []\n",
        "cvrmsescores = []\n",
        "\n",
        "for train_ix, test_ix in kfold.split(X_train):\n",
        "  # split data\n",
        "  X_trian_n, X_test_n = X_train[train_ix], X_train[test_ix]\n",
        "  y_trian_n, y_test_n = y_train[train_ix], y_train[test_ix]\n",
        "  # create model\n",
        "  \n",
        "  #dnn_best_model.fit(X_trian_n,y_trian_n, epochs=1000, batch_size=32, verbose=0)\n",
        "  test_pred = dnn_best_model.predict(X_test_n)\n",
        "  r2score  = r2_score(y_test_n, test_pred)\n",
        "  rmse   = mse(y_test_n, test_pred,squared=False)\n",
        "\n",
        "  #print(\"Test R2 Score : %.2f\" %r2score)\n",
        "  #print(\"Test R2 Score : %.2f\" %rmse)\n",
        "  \n",
        "  cvr2scores.append(r2score)\n",
        "  cvrmsescores.append(rmse)\n",
        "\n",
        "print(\"The 5-cv r2 Score was: %.2f (+/-) %.2f\" % (np.mean(cvr2scores), np.std(cvr2scores)))\n",
        "print(\"The 5-cv rmse Score was: %.2f (+/-) %.2f\" % (np.mean(cvrmsescores), np.std(cvrmsescores)))\n"
      ],
      "metadata": {
        "id": "gSjw4h-Wyn6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save predicted values (to csv file)"
      ],
      "metadata": {
        "id": "28jmKkRQ7qaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PredKmax = pd.concat([pd.DataFrame(Data.dropna()[\"ID\"].reset_index(drop=True)), pd.DataFrame(y_obs), pd.DataFrame(all_preds)], axis = 1)\n",
        "PredKmax.columns = [\"ID\",\"KTRESmax\", \"Pred_KTRESmax\"]\n",
        "PredKmax.to_csv('output_KTRESmax.csv', encoding = 'utf-8-sig',index=False)"
      ],
      "metadata": {
        "id": "qxKEfAq77tBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}